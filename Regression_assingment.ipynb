{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression?\n",
        "\n",
        "Answer- Simple linear regression aims to find a linear relationship to describe the correlation between an independent and possibly dependent variable."
      ],
      "metadata": {
        "id": "hSVW2nbDIHV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Answer-Key linear regression assumptions include linearity, independence, homoscedasticity, and normality, ensuring reliable results in regression analysis."
      ],
      "metadata": {
        "id": "lxLhJWd0IWYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "\n",
        "Answer-The equation y = mx + c is the general equation of any straight line where m is the gradient of the line."
      ],
      "metadata": {
        "id": "oXWXuqM1I15z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What does the intercept c represent in the equation Y=mX+c?\n",
        "\n",
        "Answer-The intercept c represent the height at which the line crosses the y -axis"
      ],
      "metadata": {
        "id": "_JehbssXI8AR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-We need to divide the standard deviation of y values by the standard deviation of x values and then multiply this by the correlation between x and y. The slope can be negative, which would show a line going downhill rather than upwards."
      ],
      "metadata": {
        "id": "ZXAAuV6-JL9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-Least squares is a method to apply linear regression. It helps us predict results based on an existing set of data as well as clear anomalies in our data. Anomalies are values that are too good, or bad, to be true or that represent rare cases."
      ],
      "metadata": {
        "id": "M3E5nSAxJRyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-The coefficient of determination (R¬≤) represents the proportion of variance in the dependent variable that is explained by the independent variable, essentially indicating how well the regression line fits the data; a higher R¬≤ value means a better fit, with a value of 1 signifying a perfect fit where all the variance is explained by the model and a value of 0 meaning the model explains none of the variance"
      ],
      "metadata": {
        "id": "5hq5urVoJcGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.  What is Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable and two or more independent variables using a straight line."
      ],
      "metadata": {
        "id": "4ooB5lqfJh2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.  What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-\n",
        "\n",
        "\n",
        "Simple linear regression -Analyzes the relationship between a single independent variable and a dependent variable.\n",
        "\n",
        "\n",
        "Multiple linear regression - Analyzes the relationship between multiple independent variables and a dependent variable."
      ],
      "metadata": {
        "id": "8sZ__pQuJpLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-The core premise of multiple linear regression is the existence of a linear relationship between the dependent (outcome) variable and the independent variables. One can view this linearity visually using scatterplots, which should reveal a linear relationship rather than a curvilinear one."
      ],
      "metadata": {
        "id": "OcClvN1aKDdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 11.What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "\n",
        " Answer-Heteroscedasticity means unequal scatter. In regression analysis, we talk about heteroscedasticity in the context of the residuals or error term. Specifically, heteroscedasticity is a systematic change in the spread of the residuals over the range of measured values.\n",
        "\n"
      ],
      "metadata": {
        "id": "6M5HldGNKuCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "\n",
        "Answer-remove highly correlated independent variables, use regularization techniques like Ridge or Lasso regression, combine correlated variables into a single new variable, perform dimensionality reduction using Principal Component Analysis (PCA), or increase the sample size if possible; always carefully analyzing the impact of these methods on your model's interpretability and considering the context of your data."
      ],
      "metadata": {
        "id": "Z4EAHrWnLbGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.  What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "Answer- ne-hot encoding (dummy variable encoding), where each category is represented by a separate binary feature, label encoding which assigns a unique numerical value to each category, and binary encoding which creates a binary representation for each category based on a chosen reference level; all aiming to convert categorical data into numerical values that can be used in regression analysis."
      ],
      "metadata": {
        "id": "jVlvfvdoKyDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "Answer-In multiple linear regression, interaction terms are used to capture how the effect of one independent variable on the dependent variable changes depending on the level of another independent variable, essentially allowing the model to account for situations where the combined effect of two variables is not simply additive but interactive, meaning the relationship between them is more complex than just their individual effects."
      ],
      "metadata": {
        "id": "I2QKol4VLSyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-In simple linear regression, the intercept represents the predicted value of the dependent variable when the independent variable is zero, while in multiple linear regression, the intercept represents the predicted value of the dependent variable when all independent variables are set to zero; the key difference being that multiple regression considers the combined effect of multiple variables, making the intercept interpretation more complex if not all variables have a meaningful \"zero\" point."
      ],
      "metadata": {
        "id": "rH2W6HbcLit8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "Answer-A significance test for the slope of a regression model is a way to determine whether or not there is a linear relationship between two variables. The null hypothesis is that the slope is 0 (no linear relationship)."
      ],
      "metadata": {
        "id": "nhdmw1k6L6Fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "\n",
        "Answer-In a regression model, the intercept represents the predicted value of the dependent variable when all independent variables are set to zero, essentially providing a baseline understanding of the relationship between variables by indicating where the regression line crosses the y-axis, thus giving context about the starting point of the relationship even when the independent variable has no effect."
      ],
      "metadata": {
        "id": "_Yjr6Ex9Mqb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. What are the limitations of using R¬≤ as a sole measure of model performance?\n",
        "\n",
        "\n",
        "answer- R-squared will give you an estimate of the relationship between movements of a dependent variable based on an independent variable's movements."
      ],
      "metadata": {
        "id": "3IZqX3B5NMxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "\n",
        "Answer-A large standard error for a regression coefficient indicates that the estimated coefficient is likely to vary significantly if you were to repeat the analysis with different samples from the population, meaning there is less confidence in the precision of the coefficient estimate and it may not be a reliable predictor of the relationship between the variables involved."
      ],
      "metadata": {
        "id": "HPdDV1c4Oi_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.  How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "\n",
        "Answer-Heteroscedasticity in a residual plot is typically identified by a \"fan\" or \"cone\" shape, where the spread of the residuals increases as the fitted values increase, indicating that the variance of the errors is not constant across the range of predicted values; it's important to address heteroscedasticity because it can lead to unreliable hypothesis tests and confidence intervals in your regression model, making it difficult to accurately interpret the relationship between variables."
      ],
      "metadata": {
        "id": "rCLRZbdOO6dB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?\n",
        "\n",
        "\n",
        "Answer-Compared to a model with additional input variables, a lower adjusted R-squared indicates that the additional input variables are not adding value to the model."
      ],
      "metadata": {
        "id": "MKabJO0vPXby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Answer-One such case is when the variables have different units of measurement or different scales. In these situations, scaling can help in achieving a more balanced representation of the variables, making the model more robust."
      ],
      "metadata": {
        "id": "LOAqdpxXPpfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.  What is polynomial regression?\n",
        "\n",
        "\n",
        "Answer-Polynomial regression is a machine learning technique that models non-linear relationships between variables. It's an extension of linear regression, which assumes a linear relationship between variables."
      ],
      "metadata": {
        "id": "kgxZgeqSQC1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.  How does polynomial regression differ from linear regression?\n",
        "\n",
        "\n",
        "Answer-Polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial. Unlike linear regression, polynomial regression can fit non-linear relationships between variables."
      ],
      "metadata": {
        "id": "wbsg2HkfQQ_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. When is polynomial regression used?\n",
        "\n",
        "\n",
        "\n",
        "Answer-Polynomial regression is a machine learning technique used to model non-linear relationships between variables. It's used when there's no linear correlation between the variables."
      ],
      "metadata": {
        "id": "q68s7VulQf8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "26. - What is the general equation for polynomial regression?\n",
        "\n",
        "Answer-You are using polynomial regression when you predict Y using a single X variable together with some of its powers (X2, X3, etc.). Let us consider just the case of X with X2. With these variables, the usual multiple regression equation, Y = a + b1X1 + b2X2, becomes the quadratic polynomial Y = a + b1X + b2X2."
      ],
      "metadata": {
        "id": "wZNONlAiQuQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "\n",
        "Answer- Yes, polynomial regression can be applied to multiple variables, which is often referred to as \"multivariate polynomial regression\"; it allows you to model non-linear relationships between a dependent variable and several independent variables by raising each independent variable to different powers, essentially creating a polynomial equation with multiple variables involved."
      ],
      "metadata": {
        "id": "-pRc49MtRIG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "28.  What are the limitations of polynomial regression?\n",
        "\n",
        "\n",
        "Answer-Higher-degree polynomial models are susceptible to overfitting, where the model fits the training data too closely and loses generalization ability. Careful model selection and regularization techniques are required to mitigate this risk."
      ],
      "metadata": {
        "id": "gB6-DcOeRcJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "\n",
        "Answer-When selecting the degree of a polynomial to achieve the best model fit, common evaluation methods include: visual inspection of the fitted curve, using metrics like R-squared, adjusted R-squared, mean squared error (MSE), cross-validation with a separate validation set, and comparing the performance on both training and validation sets to identify overfitting; essentially aiming to find a balance between capturing the data's curvature and avoiding excessive complexity that leads to overfitting.\n"
      ],
      "metadata": {
        "id": "0mWxwf99RqoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Why is visualization important in polynomial regression?\n",
        "\n",
        "\n",
        "Answer-Visualization is crucial in polynomial regression because it allows you to visually assess how well the fitted polynomial curve captures the non-linear relationship in your data, providing insights into whether the model is accurately representing the underlying pattern and identifying potential issues like overfitting or underfitting by comparing the plotted curve with the actual data points."
      ],
      "metadata": {
        "id": "bpVrj4tHR7oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "31. How is polynomial regression implemented in Python?\n",
        "\n",
        "\n",
        "\n",
        "Answer- Implementing linear regression in Python involves using libraries like scikit-learn and statsmodels to fit models and make predictions. The formula for linear regression is ùë¶ = ùõΩ‚ÇÄ + ùõΩ‚ÇÅùë•‚ÇÅ + ‚ãØ + ùõΩ·µ£ùë•·µ£ + ùúÄ, representing the linear relationship between variables."
      ],
      "metadata": {
        "id": "-Fbt5N1kSIgn"
      }
    }
  ]
}